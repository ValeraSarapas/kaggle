{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning: Mnist Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "\n",
    "from sympy import Symbol\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda, Dense\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow for each analysis type (e.g basic, 1 Dense layer...):\n",
    "\n",
    "1. Create model\n",
    "2. Train it with the default \"Learning Rate\" of 0.01 just 1 epoch so we see the speed with what the accuracy is increasing.\n",
    "3. Increase the \"Learning Rate\" to 0.1 and train the model between 4 and 12 epochs.\n",
    "4. Decrease the \"Learning Rate\" to 0.01 and train the model 4 epochs.\n",
    "5. Decrease the \"Learning Rate\" to 0.001 and train the model 2 epochs.\n",
    "6. Decrease the \"Learning Rate\" to 0.0001 and train the model 1 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We set the \"seed\" so we make the results a bit more predictable.\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.pkl.gz\n",
      "15171584/15296311 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Let's load the data. Mnist can be loaded really easily with Keras!\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keras needs to have at least one channel (color), so we expand the dimensions here.\n",
    "X_test = np.expand_dims(X_test,1)\n",
    "X_train = np.expand_dims(X_train,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We would like to have an output in the form: [0, 0, 1, 0...] so we transform the labels with\n",
    "# \"onehot\".\n",
    "y_train = onehot(y_train)\n",
    "y_test = onehot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We normalize the inputs so the training is more stable.\n",
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's start by implementing a really basic Linear Model.\n",
    "model = Sequential([\n",
    "    Lambda(norm_input, input_shape=(1,28,28)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This class creates batches based on images in \"array-form\". It's also quite powerful\n",
    "# as it allows us to do Data Augmentation.\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 11s - loss: 0.4208 - acc: 0.8753 - val_loss: 0.2939 - val_acc: 0.9157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfda318190>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We train the model with the batches.\n",
    "model.fit_generator(batches, batches.N, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We increase the learning rate until we get overfitting.\n",
    "model.optimizer.lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 11s - loss: 0.3002 - acc: 0.9144 - val_loss: 0.2811 - val_acc: 0.9237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfd92fc510>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We decrease the learning rate as we want it to go slower because our accuracy\n",
    "# didn't increase too much in the last step.\n",
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 11s - loss: 0.2840 - acc: 0.9200 - val_loss: 0.2714 - val_acc: 0.9240\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 11s - loss: 0.2791 - acc: 0.9222 - val_loss: 0.2870 - val_acc: 0.9201\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 11s - loss: 0.2725 - acc: 0.9237 - val_loss: 0.2734 - val_acc: 0.9210\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 12s - loss: 0.2693 - acc: 0.9255 - val_loss: 0.2770 - val_acc: 0.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfd92fc890>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We train the model with the batches 4 times so we reach overfitting.\n",
    "model.fit_generator(batches, batches.N, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are still underfitting! Our model is clearly not complex enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We add a new hidden dense layer and follow the same process as before.\n",
    "model = Sequential([\n",
    "    Lambda(norm_input, input_shape=(1,28,28)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='softmax'),\n",
    "    Dense(10, activation='softmax')\n",
    "    ])\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 12s - loss: 1.5467 - acc: 0.8874 - val_loss: 1.0143 - val_acc: 0.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfd90ea510>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 12s - loss: 0.7422 - acc: 0.9279 - val_loss: 0.5531 - val_acc: 0.9295\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 12s - loss: 0.4504 - acc: 0.9349 - val_loss: 0.3907 - val_acc: 0.9318\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 12s - loss: 0.3460 - acc: 0.9371 - val_loss: 0.3189 - val_acc: 0.9356\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 12s - loss: 0.2984 - acc: 0.9395 - val_loss: 0.3073 - val_acc: 0.9337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfd8862d50>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 12s - loss: 0.2705 - acc: 0.9424 - val_loss: 0.2842 - val_acc: 0.9371\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 12s - loss: 0.2512 - acc: 0.9453 - val_loss: 0.2761 - val_acc: 0.9386\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 12s - loss: 0.2373 - acc: 0.9470 - val_loss: 0.2635 - val_acc: 0.9385\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 12s - loss: 0.2288 - acc: 0.9476 - val_loss: 0.2782 - val_acc: 0.9340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfd8862e50>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are clearly overfitting this time!\n",
    "# Meaning that the accuracy of the training data is much higher than the one in the\n",
    "# validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-Style CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we try out a VGG-style model, with several Convolution2D layers and MaxPooling2D.\n",
    "model = Sequential([\n",
    "    Lambda(norm_input, input_shape=(1,28,28)),\n",
    "    Convolution2D(32,3,3, activation='relu'),\n",
    "    Convolution2D(32,3,3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Convolution2D(64,3,3, activation='relu'),\n",
    "    Convolution2D(64,3,3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "    ])\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 20s - loss: 0.1093 - acc: 0.9658 - val_loss: 0.0321 - val_acc: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfd41db690>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 20s - loss: 0.0335 - acc: 0.9902 - val_loss: 0.0288 - val_acc: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfc9cb22d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 20s - loss: 0.0259 - acc: 0.9920 - val_loss: 0.0267 - val_acc: 0.9906\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 20s - loss: 0.0196 - acc: 0.9939 - val_loss: 0.0230 - val_acc: 0.9931\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 20s - loss: 0.0150 - acc: 0.9952 - val_loss: 0.0247 - val_acc: 0.9941\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 20s - loss: 0.0131 - acc: 0.9955 - val_loss: 0.0204 - val_acc: 0.9939\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 20s - loss: 0.0109 - acc: 0.9964 - val_loss: 0.0232 - val_acc: 0.9945\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 20s - loss: 0.0091 - acc: 0.9974 - val_loss: 0.0251 - val_acc: 0.9937\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 20s - loss: 0.0080 - acc: 0.9975 - val_loss: 0.0277 - val_acc: 0.9933\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 20s - loss: 0.0092 - acc: 0.9970 - val_loss: 0.0301 - val_acc: 0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfc9cb2450>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=8, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This result is incredible! But we are overfitting, let's introduce \"Data Augmentation\" so\n",
    "# we can deal with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Lambda(norm_input, input_shape=(1,28,28)),\n",
    "    Convolution2D(32,3,3, activation='relu'),\n",
    "    Convolution2D(32,3,3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Convolution2D(64,3,3, activation='relu'),\n",
    "    Convolution2D(64,3,3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "    ])\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This command will randomly modify the images (e.g rotation, zoom, ...) so it seems like we have more\n",
    "# images.\n",
    "gen = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 19s - loss: 0.1981 - acc: 0.9376 - val_loss: 0.0779 - val_acc: 0.9747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfc883a990>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 20s - loss: 0.0720 - acc: 0.9780 - val_loss: 0.0497 - val_acc: 0.9831\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 19s - loss: 0.0563 - acc: 0.9821 - val_loss: 0.0484 - val_acc: 0.9836\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 20s - loss: 0.0455 - acc: 0.9859 - val_loss: 0.0401 - val_acc: 0.9876\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 20s - loss: 0.0438 - acc: 0.9864 - val_loss: 0.0387 - val_acc: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfc7eba190>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 19s - loss: 0.0373 - acc: 0.9886 - val_loss: 0.0320 - val_acc: 0.9881\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 19s - loss: 0.0380 - acc: 0.9882 - val_loss: 0.0342 - val_acc: 0.9898\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 19s - loss: 0.0343 - acc: 0.9891 - val_loss: 0.0408 - val_acc: 0.9869\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 19s - loss: 0.0325 - acc: 0.9899 - val_loss: 0.0279 - val_acc: 0.9919\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 19s - loss: 0.0306 - acc: 0.9905 - val_loss: 0.0273 - val_acc: 0.9917\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 20s - loss: 0.0296 - acc: 0.9907 - val_loss: 0.0304 - val_acc: 0.9904\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 19s - loss: 0.0282 - acc: 0.9914 - val_loss: 0.0315 - val_acc: 0.9918\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 19s - loss: 0.0259 - acc: 0.9920 - val_loss: 0.0310 - val_acc: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfc7eba4d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=8, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 20s - loss: 0.0260 - acc: 0.9921 - val_loss: 0.0414 - val_acc: 0.9880\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 20s - loss: 0.0253 - acc: 0.9917 - val_loss: 0.0310 - val_acc: 0.9906\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 20s - loss: 0.0228 - acc: 0.9927 - val_loss: 0.0340 - val_acc: 0.9908\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 20s - loss: 0.0234 - acc: 0.9927 - val_loss: 0.0263 - val_acc: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfc7eba090>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not bad, we are still overfitting but much less! Let's see other techniques that might be\n",
    "# useful in your analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization + Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's apply now \"Batch Normalization\" to normalize the different weights in the CNN.\n",
    "model = Sequential([\n",
    "    Lambda(norm_input, input_shape=(1,28,28)),\n",
    "    Convolution2D(32,3,3, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    Convolution2D(32,3,3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    BatchNormalization(axis=1),\n",
    "    Convolution2D(64,3,3, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    Convolution2D(64,3,3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    BatchNormalization(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation='softmax')\n",
    "    ])\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 47s - loss: 0.1600 - acc: 0.9507 - val_loss: 0.0681 - val_acc: 0.9795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfc3bb4490>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 46s - loss: 0.0709 - acc: 0.9776 - val_loss: 0.0438 - val_acc: 0.9849\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 46s - loss: 0.0598 - acc: 0.9811 - val_loss: 0.0419 - val_acc: 0.9867\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 46s - loss: 0.0517 - acc: 0.9834 - val_loss: 0.0522 - val_acc: 0.9843\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 46s - loss: 0.0488 - acc: 0.9852 - val_loss: 0.0374 - val_acc: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfc3bb4590>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 46s - loss: 0.0423 - acc: 0.9866 - val_loss: 0.0416 - val_acc: 0.9869\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 46s - loss: 0.0432 - acc: 0.9866 - val_loss: 0.0373 - val_acc: 0.9877\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 46s - loss: 0.0387 - acc: 0.9879 - val_loss: 0.0297 - val_acc: 0.9907\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 46s - loss: 0.0359 - acc: 0.9888 - val_loss: 0.0358 - val_acc: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfc7768a90>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 46s - loss: 0.0336 - acc: 0.9891 - val_loss: 0.0402 - val_acc: 0.9874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfc7ebaad0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization + Data Augmentation + Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are overfitting again, let's add a Dropout layer\n",
    "def get_model_bn_do():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "model = get_model_bn_do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 45s - loss: 0.2195 - acc: 0.9344 - val_loss: 0.0652 - val_acc: 0.9796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfab895110>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 45s - loss: 0.0921 - acc: 0.9710 - val_loss: 0.0461 - val_acc: 0.9840\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 45s - loss: 0.0752 - acc: 0.9766 - val_loss: 0.0406 - val_acc: 0.9871\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 45s - loss: 0.0673 - acc: 0.9792 - val_loss: 0.0348 - val_acc: 0.9884\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 45s - loss: 0.0632 - acc: 0.9804 - val_loss: 0.0398 - val_acc: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfab8959d0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 45s - loss: 0.0570 - acc: 0.9828 - val_loss: 0.0400 - val_acc: 0.9877\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 45s - loss: 0.0525 - acc: 0.9840 - val_loss: 0.0430 - val_acc: 0.9871\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 45s - loss: 0.0483 - acc: 0.9841 - val_loss: 0.0308 - val_acc: 0.9911\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 45s - loss: 0.0480 - acc: 0.9855 - val_loss: 0.0295 - val_acc: 0.9916\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 45s - loss: 0.0459 - acc: 0.9861 - val_loss: 0.0295 - val_acc: 0.9897\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 45s - loss: 0.0437 - acc: 0.9869 - val_loss: 0.0294 - val_acc: 0.9915\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 45s - loss: 0.0414 - acc: 0.9872 - val_loss: 0.0242 - val_acc: 0.9914\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 45s - loss: 0.0417 - acc: 0.9873 - val_loss: 0.0338 - val_acc: 0.9909\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 45s - loss: 0.0380 - acc: 0.9884 - val_loss: 0.0352 - val_acc: 0.9895\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 45s - loss: 0.0393 - acc: 0.9881 - val_loss: 0.0264 - val_acc: 0.9918\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 45s - loss: 0.0359 - acc: 0.9892 - val_loss: 0.0272 - val_acc: 0.9920\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 45s - loss: 0.0365 - acc: 0.9891 - val_loss: 0.0240 - val_acc: 0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfb202fdd0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=12, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 45s - loss: 0.0336 - acc: 0.9895 - val_loss: 0.0271 - val_acc: 0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfb202f0d0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's try finally with \"Ensembling\"\n",
    "def fit_model():\n",
    "    model = get_model_bn_do()\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=1, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.N)\n",
    "    model.optimizer.lr=0.1\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=4, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.N)\n",
    "    model.optimizer.lr=0.01\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=12, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.N)\n",
    "    model.optimizer.lr=0.001\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=18, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.N)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [fit_model() for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"data/mnist/\"\n",
    "model_path = path + 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,m in enumerate(models):\n",
    "    m.save_weights(model_path+'cnn-mnist23-'+str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evals = np.array([m.evaluate(X_test, y_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evals.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(X_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.metrics.categorical_accuracy(y_test, avg_preds).eval()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
