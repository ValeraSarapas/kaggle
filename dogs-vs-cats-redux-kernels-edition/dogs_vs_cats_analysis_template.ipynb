{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning: Dogs vs Cats Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda, Dense\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow for each analysis type (e.g Default Parameter, Backpropagation...):\n",
    "\n",
    "1. Create model\n",
    "2. Train it with the default \"Learning Rate\" of 0.01 just 1 epoch so we see the speed with what the accuracy is increasing.\n",
    "3. Increase the \"Learning Rate\" to 0.1 and train the model between 4 and 12 epochs.\n",
    "4. Decrease the \"Learning Rate\" to 0.01 and train the model 4 epochs.\n",
    "5. Decrease the \"Learning Rate\" to 0.001 and train the model 2 epochs.\n",
    "6. ...\n",
    "\n",
    "All of these steps are approximate. You should play around with the output to see how the accuracy is reacting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the following lines in order to set up the Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We set the \"seed\" so we make the results a bit more predictable.\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Type 'sample/' if you want to work on a smaller dataset.\n",
    "path = ''\n",
    "# Depending on your GPU you should change this. For a GTX 970 this is a good value. \n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the timestamp that we are going to use when saving files.\n",
    "timestamp = '010108012017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some useful paths to save files (e.g weights)\n",
    "files_path = path + 'files/'\n",
    "models_path = path + 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_batches(path, augmentation=False):\n",
    "    \"\"\"\n",
    "    Load different batches that we'll use in our calculations.\n",
    "    \"\"\"\n",
    "    if augmentation:\n",
    "        gen = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.8, shear_range=0.3,\n",
    "                                       height_shift_range=0.8, zoom_range=0.8)\n",
    "    else:\n",
    "        gen = image.ImageDataGenerator()\n",
    "    train_batches = gen.flow_from_directory(path + 'train', target_size=(224,224),\n",
    "                    class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "    val_batches = gen.flow_from_directory(path + 'valid', target_size=(224,224),\n",
    "                    class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "    test_batches = gen.flow_from_directory(path + 'test', target_size=(224,224),\n",
    "                    class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "    return train_batches, val_batches, test_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finetune(model):\n",
    "    \"\"\"\n",
    "    Removes the last layer (usually Dense) and replace it by another one more fitting.\n",
    "    This is useful when using a pre-trained model like VGG.\n",
    "    \"\"\"\n",
    "    model.pop()\n",
    "    for layer in model.layers: layer.trainable=False\n",
    "    model.add(Dense(train_batches.nb_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backpropagation(model):\n",
    "    \"\"\"\n",
    "    Now we do Backpropagation. Backpropagation is when we want to train not only the last\n",
    "    Dense layer, but also some previous ones. Note that we don't train Convolutional layers.\n",
    "    \"\"\"\n",
    "    layers = model.layers\n",
    "    for layer in layers: layer.trainable=False\n",
    "    # Get the index of the first dense layer...\n",
    "    first_dense_idx = [index for index,layer in enumerate(layers) if type(layer) is Dense][0]\n",
    "    # ...and set this and all subsequent layers to trainable\n",
    "    for layer in layers[first_dense_idx:]: layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_weights(model, path, name, timestamp):\n",
    "    print 'Saving weights: {}.h5'.format(path + name + '_' + timestamp)\n",
    "    model.save_weights(path + '{}_{}.h5'.format(name, timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_weights(model, path, name, timestamp):\n",
    "    print 'Loading weights: {}.h5'.format(path + name + '_' + timestamp)\n",
    "    model.load_weights(path + '{}_{}.h5'.format(name, timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_batches, val_batches, rules, name, timestamp, optimizer_algorithm=Adam):\n",
    "    \"\"\"\n",
    "    Rules will be something like:\n",
    "        (\n",
    "            (0.01, 3),\n",
    "            (0.1, 2),\n",
    "            ...\n",
    "        )\n",
    "    \"\"\"\n",
    "    for lr, epochs in rules:\n",
    "        model.compile(optimizer=optimizer_algorithm(lr=lr),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        for i in range(epochs):\n",
    "            print 'Lr: {}, Epoch: {}'.format(lr, i + 1)\n",
    "            model.fit_generator(train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "                                nb_epoch=1, validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "            save_weights(model, files_path, '{}_lr{}_epoch{}'.format(\n",
    "                    name, lr, i+1), timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_conv_fc(model):\n",
    "    \"\"\"\n",
    "    Split Convolutional and Dense Layers.\n",
    "    \"\"\"\n",
    "    layers = model.layers\n",
    "    last_conv_idx = [index for index,layer in enumerate(layers) \n",
    "                     if type(layer) is Convolution2D][-1]\n",
    "    conv_layers = layers[:last_conv_idx+1]\n",
    "    fc_layers = layers[last_conv_idx+1:]\n",
    "    return conv_layers, fc_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Parameters (VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'default_parameter_vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches, val_batches, test_batches = load_batches(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finetune(vgg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_model(vgg.model, train_batches, val_batches, ((0.01, 2), (0.1, 1), (0.001, 4), (0.0001, 2)), name + '_lastlayer', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_weights(vgg.model, files_path, name, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_weights(vgg.model, files_path, name, timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation (VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'data_augmentation_vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_batches, val_batches, test_batches = load_batches(path, augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finetune(vgg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_model(vgg.model, train_batches, val_batches, ((0.01, 1), (0.1, 1), (0.001, 1), (0.0001, 1)), name + '_lastlayer', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_weights(vgg.model, files_path, name, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_weights(vgg.model, files_path, name, timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation - Only Dense Layers (VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'backpropagation_vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_batches, val_batches, test_batches = load_batches(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finetune(vgg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We first need to train the last layer\n",
    "train_model(vgg.model, train_batches, val_batches, ((0.01, 1)), name + '_lastlayer', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "backpropagation(vgg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For the Backpropagation the Learning rate should be quite small\n",
    "train_model(vgg.model, train_batches, val_batches, ((0.001, 1), (0.0001, 1)), name + '_denselayers', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_weights(vgg.model, files_path, name, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_weights(vgg.model, files_path, name, timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation + Backpropagation (VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'data_augmentation_backpropagation_vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_batches, val_batches, test_batches = load_batches(path, augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finetune(vgg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_model(vgg.model, train_batches, val_batches, ((0.01, 1),), name + '_lastlayer', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "backpropagation(vgg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_model(vgg.model, train_batches, val_batches, ((0.01, 1), (0.1, 1), (0.001, 1), (0.0001, 1)), name + '_denselayers', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_weights(vgg.model, files_path, name, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_weights(vgg.model, files_path, name, timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Dropout (VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'remove_dropout_vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finetune(vgg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_weights(vgg.model, files_path, 'default_parameter_vgg16', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers, fc_layers = split_conv_fc(vgg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_batches, val_batches, test_batches = load_batches(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = conv_model.predict_generator(train_batches, train_batches.nb_sample)\n",
    "val_features = conv_model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "val_classes = val_batches.classes\n",
    "train_classes = train_batches.classes\n",
    "val_labels = onehot(val_classes)\n",
    "train_labels = onehot(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(models_path + 'train_convlayer_features.bc', train_features)\n",
    "save_array(models_path + 'valid_convlayer_features.bc', val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = load_array(models_path+'train_convlayer_features.bc')\n",
    "val_features = load_array(models_path+'valid_convlayer_features.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy the weights from the pre-trained model.\n",
    "# NB: Since we're removing dropout, we want to half the weights\n",
    "def proc_wgts(layer): return [o/2 for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.),\n",
    "        Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    for l1,l2 in zip(model.layers, fc_layers): l1.set_weights(proc_wgts(l2))\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=RMSprop(lr=0.00001, rho=0.7), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40 samples, validate on 20 samples\n",
      "Epoch 1/8\n",
      "40/40 [==============================] - 0s - loss: 2.3801 - acc: 0.5500 - val_loss: 1.5106 - val_acc: 0.5500\n",
      "Epoch 2/8\n",
      "40/40 [==============================] - 0s - loss: 0.6337 - acc: 0.7250 - val_loss: 1.3585 - val_acc: 0.5500\n",
      "Epoch 3/8\n",
      "40/40 [==============================] - 0s - loss: 0.1676 - acc: 0.9500 - val_loss: 1.4263 - val_acc: 0.5500\n",
      "Epoch 4/8\n",
      "40/40 [==============================] - 0s - loss: 0.0536 - acc: 1.0000 - val_loss: 1.4398 - val_acc: 0.5500\n",
      "Epoch 5/8\n",
      "40/40 [==============================] - 0s - loss: 0.0158 - acc: 1.0000 - val_loss: 1.5356 - val_acc: 0.6000\n",
      "Epoch 6/8\n",
      "40/40 [==============================] - 0s - loss: 0.0064 - acc: 1.0000 - val_loss: 1.6152 - val_acc: 0.5500\n",
      "Epoch 7/8\n",
      "40/40 [==============================] - 0s - loss: 0.0025 - acc: 1.0000 - val_loss: 1.6737 - val_acc: 0.5000\n",
      "Epoch 8/8\n",
      "40/40 [==============================] - 0s - loss: 8.6576e-04 - acc: 1.0000 - val_loss: 1.7841 - val_acc: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa0e3644050>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_fc_model()\n",
    "model.fit(train_features, train_labels, nb_epoch=8, \n",
    "          batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_weights(vgg.model, files_path, name, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_weights(vgg.model, files_path, name, timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing model prediction examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A few correct labels at random\n",
    "* A few incorrect labels at random\n",
    "* The most correct labels of each class (ie those with highest probability that are correct)\n",
    "* The most incorrect labels of each class (ie those with highest probability that are incorrect)\n",
    "* The most uncertain labels (ie those with probability closest to 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_batches, probs = vgg.test(path + 'valid', batch_size = batch_size)\n",
    "\n",
    "filenames = val_batches.filenames\n",
    "expected_labels = val_batches.classes #0 or 1\n",
    "\n",
    "#Round our predictions to 0/1 to generate labels\n",
    "our_predictions = probs[:,0]\n",
    "our_labels = np.round(1-our_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#Helper function to plot images by index in the validation set \n",
    "#Plots is a helper function in utils.py\n",
    "def plots_idx(idx, titles=None):\n",
    "    plots([image.load_img(path + 'valid/' + filenames[i]) for i in idx], titles=titles)\n",
    "    \n",
    "#Number of images to view for each visualization task\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1. A few correct labels at random\n",
    "correct = np.where(our_labels==expected_labels)[0]\n",
    "print \"Found %d correct labels\" % len(correct)\n",
    "idx = permutation(correct)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2. A few incorrect labels at random\n",
    "incorrect = np.where(our_labels!=expected_labels)[0]\n",
    "print \"Found %d incorrect labels\" % len(incorrect)\n",
    "idx = permutation(incorrect)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3a. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((our_labels==0) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct cats labels\" % len(correct_cats)\n",
    "most_correct_cats = np.argsort(our_predictions[correct_cats])[::-1][:n_view]\n",
    "plots_idx(correct_cats[most_correct_cats], our_predictions[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3b. The images we most confident were dogs, and are actually dogs\n",
    "correct_dogs = np.where((our_labels==1) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct dogs labels\" % len(correct_dogs)\n",
    "most_correct_dogs = np.argsort(our_predictions[correct_dogs])[:n_view]\n",
    "plots_idx(correct_dogs[most_correct_dogs], our_predictions[correct_dogs][most_correct_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4a. The images we were most confident were cats, but are actually dogs\n",
    "incorrect_cats = np.where((our_labels==0) & (our_labels!=expected_labels))[0]\n",
    "print \"Found %d incorrect cats\" % len(incorrect_cats)\n",
    "if len(incorrect_cats):\n",
    "    most_incorrect_cats = np.argsort(our_predictions[incorrect_cats])[::-1][:n_view]\n",
    "    plots_idx(incorrect_cats[most_incorrect_cats], our_predictions[incorrect_cats][most_incorrect_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4b. The images we were most confident were dogs, but are actually cats\n",
    "incorrect_dogs = np.where((our_labels==1) & (our_labels!=expected_labels))[0]\n",
    "print \"Found %d incorrect dogs\" % len(incorrect_dogs)\n",
    "if len(incorrect_dogs):\n",
    "    most_incorrect_dogs = np.argsort(our_predictions[incorrect_dogs])[:n_view]\n",
    "    plots_idx(incorrect_dogs[most_incorrect_dogs], our_predictions[incorrect_dogs][most_incorrect_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "most_uncertain = np.argsort(np.abs(our_predictions-0.5))\n",
    "plots_idx(most_uncertain[:n_view], our_predictions[most_uncertain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confussion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test set + create Kaggle submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = vgg.model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isdog = predictions[:,1]\n",
    "print \"Raw Predictions: \" + str(isdog[:5])\n",
    "print \"Mid Predictions: \" + str(isdog[(isdog < .6) & (isdog > .4)])\n",
    "print \"Edge Predictions: \" + str(isdog[(isdog == 1) | (isdog == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isdog = isdog.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract imageIds from the filenames in our test/unknown directory \n",
    "filenames = test_batches.filenames\n",
    "\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subm = np.stack([ids,isdog], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_file_name = 'submission_{}_5.csv'.format(timestamp)\n",
    "np.savetxt(submission_file_name, subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(submission_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative way to generate Submission file (it has a better score!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_submission_csv(submission_file_name, data, columns):\n",
    "    \"\"\"\n",
    "    Write data according to the Kaggle submission format.\n",
    "    \"\"\"\n",
    "    with open(submission_file_name, 'wb') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(columns)\n",
    "        for key in data.keys():\n",
    "            w.writerow([key, data[key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_batches, predictions = vgg.test(path+'test', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "d = {}\n",
    "submission_file_name = 'submission_{}_5.csv'.format(timestamp)\n",
    "for idx, filename in enumerate(test_batches.filenames):\n",
    "    # We only want the ID, so remove the folder name and file extension.\n",
    "    result = int(filename[8:-4])\n",
    "    # We use a trick to never show 0 or 1, but 0.05 and 0.95.\n",
    "    # This is required becase log loss penalizes predictions that are confident and wrong.\n",
    "    d[result] = predictions[idx][1].clip(min=0.05, max=0.95)\n",
    "write_submission_csv(submission_file_name, d, ['id', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(submission_file_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
